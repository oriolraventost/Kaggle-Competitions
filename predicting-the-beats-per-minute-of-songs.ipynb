{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91720,"databundleVersionId":13345277,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### **1. INTRODUCTION**\n\nThis notebook presents a solution to the [Playground Series - Season 5, Episode 9](https://www.kaggle.com/competitions/playground-series-s5e9) Kaggle competition, held in September 2025. The goal is to predict a song's beats-per-minute, with submissions evaluated using the Root Mean Squared Error (RMSE) between predicted and observed targets.\n\nThe workflow begins with importing the necessary libraries, followed by loading the training and testing datasets. A basic exploratory data analysis (EDA) is then performed, including examining shapes, structure, summary statistics, and other key information for both DataFrames.\n\nNext, feature engineering is carried out. Pairwise and triplet combinations of columns are created to generate additional features, and the quartile and decile for each column's values are computed.\n\nIn the modeling stage, XGBoost and LightGBM models are defined with appropriate hyperparameters and trained using 5-fold cross-validation. In each fold, models are trained on the training set, and predictions are made for both the validation fold and the test data (the latter averaged across folds). Out-of-fold predictions are then compared to the true target values to calculate cross-validation RMSE.\n\nFinally, predictions from both models are blended by averaging, and a new cross-validation RMSE is computed. A CSV file containing the averaged test set predictions is created for submission to the competition.\n\n#### **2. IMPORT LIBRARIES**\n\nFirst, we import all the libraries required for this notebook. NumPy is used for numerical operations and Pandas for data manipulation. Fore and Style from colorama are used to display exploratory data analysis. Combinations from itertools are imported to generate feature interactions during feature engineering. XGBRegressor and LGBMRegressor from xgboost and lightgbm, respectively, are used for model training. Finally, KFold and mean_squared_error from scikit-learn are used for cross-validation and regression evaluation.","metadata":{}},{"cell_type":"code","source":"# ===== IMPORT LIBRARIES =====\nimport numpy as np\nimport pandas as pd\nfrom colorama import Fore, Style\nfrom itertools import combinations\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:10:56.363163Z","iopub.execute_input":"2025-09-07T16:10:56.363916Z","iopub.status.idle":"2025-09-07T16:11:03.299619Z","shell.execute_reply.started":"2025-09-07T16:10:56.363875Z","shell.execute_reply":"2025-09-07T16:11:03.298745Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"#### **3. LOAD DATA**\n\nIn this step, the training and testing datasets are loaded from files as pandas DataFrames. The id column is set as the index of both DataFrames to ensure unique identification and alignment.","metadata":{}},{"cell_type":"code","source":"# ===== LOAD DATA =====\nX = pd.read_csv('/kaggle/input/playground-series-s5e9/train.csv').set_index('id')\nX_test = pd.read_csv('/kaggle/input/playground-series-s5e9/test.csv').set_index('id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:11:06.325063Z","iopub.execute_input":"2025-09-07T16:11:06.325695Z","iopub.status.idle":"2025-09-07T16:11:08.148880Z","shell.execute_reply.started":"2025-09-07T16:11:06.325667Z","shell.execute_reply":"2025-09-07T16:11:08.147866Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"#### **4. EXPLORE DATA**\n\nNext, we perform basic exploratory data analysis (EDA), examining the shapes, heads, information, descriptions, and the number of unique and missing values for both the training and testing datasets.\n","metadata":{}},{"cell_type":"code","source":"# ===== EXPLORE DATA =====\ndef display_eda(dfs, names, target):\n    print(f\"{Fore.BLUE}{'-'*50}\\n{names[0]} | SHAPE = {dfs[0].shape}\\n{names[1]} | SHAPE = {dfs[1].shape}{Style.RESET_ALL}\")\n    \n    for name, df in zip(names, dfs):\n        print(f\"{Fore.CYAN}{'-'*50}\\n{name} head:{Style.RESET_ALL}\")\n        display(df.head().style.format(precision=3))\n    \n    print(f\"{Fore.MAGENTA}{'-'*50}\\nInformation and description{Style.RESET_ALL}\")\n    for i, (name, df) in enumerate(zip(names, dfs)):\n        print(f\"{Fore.BLUE}{'-'*50}\\n{name} description:{Style.RESET_ALL}\")\n        display(df.drop(columns=[target], errors='ignore').describe().round(2))\n        \n        print(f\"{Fore.BLUE}{'-'*50}\\n{name} information:{Style.RESET_ALL}\")\n        display(df.info())\n    \n    print(f\"{Fore.BLUE}{'-'*50}\\nUnique and null values:{Style.RESET_ALL}\")\n    info_df = pd.concat([\n        dfs[0].drop(columns=[target], errors='ignore').nunique(),\n        dfs[1].drop(columns=[target], errors='ignore').nunique(),\n        dfs[0].drop(columns=[target], errors='ignore').isna().sum(),\n        dfs[1].drop(columns=[target], errors='ignore').isna().sum()\n    ], axis=1)\n    \n    info_df.columns = ['Training_Nunq', 'Testing_Nunq', 'Training_Nulls', 'Testing_Nulls']\n    display(info_df.T.style.format(formatter='{:.0f}'))\n\ndisplay_eda(dfs=[X, X_test], names=['Training data', 'Testing data'], target='BeatsPerMinute')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:11:09.809309Z","iopub.execute_input":"2025-09-07T16:11:09.809912Z","iopub.status.idle":"2025-09-07T16:11:10.668565Z","shell.execute_reply.started":"2025-09-07T16:11:09.809886Z","shell.execute_reply":"2025-09-07T16:11:10.667771Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m--------------------------------------------------\nTraining data | SHAPE = (524164, 10)\nTesting data | SHAPE = (174722, 9)\u001b[0m\n\u001b[36m--------------------------------------------------\nTraining data head:\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7c182e81e110>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_be39e\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_be39e_level0_col0\" class=\"col_heading level0 col0\" >RhythmScore</th>\n      <th id=\"T_be39e_level0_col1\" class=\"col_heading level0 col1\" >AudioLoudness</th>\n      <th id=\"T_be39e_level0_col2\" class=\"col_heading level0 col2\" >VocalContent</th>\n      <th id=\"T_be39e_level0_col3\" class=\"col_heading level0 col3\" >AcousticQuality</th>\n      <th id=\"T_be39e_level0_col4\" class=\"col_heading level0 col4\" >InstrumentalScore</th>\n      <th id=\"T_be39e_level0_col5\" class=\"col_heading level0 col5\" >LivePerformanceLikelihood</th>\n      <th id=\"T_be39e_level0_col6\" class=\"col_heading level0 col6\" >MoodScore</th>\n      <th id=\"T_be39e_level0_col7\" class=\"col_heading level0 col7\" >TrackDurationMs</th>\n      <th id=\"T_be39e_level0_col8\" class=\"col_heading level0 col8\" >Energy</th>\n      <th id=\"T_be39e_level0_col9\" class=\"col_heading level0 col9\" >BeatsPerMinute</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >id</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n      <th class=\"blank col3\" >&nbsp;</th>\n      <th class=\"blank col4\" >&nbsp;</th>\n      <th class=\"blank col5\" >&nbsp;</th>\n      <th class=\"blank col6\" >&nbsp;</th>\n      <th class=\"blank col7\" >&nbsp;</th>\n      <th class=\"blank col8\" >&nbsp;</th>\n      <th class=\"blank col9\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_be39e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_be39e_row0_col0\" class=\"data row0 col0\" >0.604</td>\n      <td id=\"T_be39e_row0_col1\" class=\"data row0 col1\" >-7.637</td>\n      <td id=\"T_be39e_row0_col2\" class=\"data row0 col2\" >0.024</td>\n      <td id=\"T_be39e_row0_col3\" class=\"data row0 col3\" >0.000</td>\n      <td id=\"T_be39e_row0_col4\" class=\"data row0 col4\" >0.000</td>\n      <td id=\"T_be39e_row0_col5\" class=\"data row0 col5\" >0.051</td>\n      <td id=\"T_be39e_row0_col6\" class=\"data row0 col6\" >0.410</td>\n      <td id=\"T_be39e_row0_col7\" class=\"data row0 col7\" >290715.645</td>\n      <td id=\"T_be39e_row0_col8\" class=\"data row0 col8\" >0.826</td>\n      <td id=\"T_be39e_row0_col9\" class=\"data row0 col9\" >147.530</td>\n    </tr>\n    <tr>\n      <th id=\"T_be39e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_be39e_row1_col0\" class=\"data row1 col0\" >0.639</td>\n      <td id=\"T_be39e_row1_col1\" class=\"data row1 col1\" >-16.268</td>\n      <td id=\"T_be39e_row1_col2\" class=\"data row1 col2\" >0.072</td>\n      <td id=\"T_be39e_row1_col3\" class=\"data row1 col3\" >0.445</td>\n      <td id=\"T_be39e_row1_col4\" class=\"data row1 col4\" >0.349</td>\n      <td id=\"T_be39e_row1_col5\" class=\"data row1 col5\" >0.171</td>\n      <td id=\"T_be39e_row1_col6\" class=\"data row1 col6\" >0.651</td>\n      <td id=\"T_be39e_row1_col7\" class=\"data row1 col7\" >164519.517</td>\n      <td id=\"T_be39e_row1_col8\" class=\"data row1 col8\" >0.145</td>\n      <td id=\"T_be39e_row1_col9\" class=\"data row1 col9\" >136.160</td>\n    </tr>\n    <tr>\n      <th id=\"T_be39e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_be39e_row2_col0\" class=\"data row2 col0\" >0.515</td>\n      <td id=\"T_be39e_row2_col1\" class=\"data row2 col1\" >-15.954</td>\n      <td id=\"T_be39e_row2_col2\" class=\"data row2 col2\" >0.111</td>\n      <td id=\"T_be39e_row2_col3\" class=\"data row2 col3\" >0.174</td>\n      <td id=\"T_be39e_row2_col4\" class=\"data row2 col4\" >0.454</td>\n      <td id=\"T_be39e_row2_col5\" class=\"data row2 col5\" >0.030</td>\n      <td id=\"T_be39e_row2_col6\" class=\"data row2 col6\" >0.424</td>\n      <td id=\"T_be39e_row2_col7\" class=\"data row2 col7\" >174495.567</td>\n      <td id=\"T_be39e_row2_col8\" class=\"data row2 col8\" >0.625</td>\n      <td id=\"T_be39e_row2_col9\" class=\"data row2 col9\" >55.320</td>\n    </tr>\n    <tr>\n      <th id=\"T_be39e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_be39e_row3_col0\" class=\"data row3 col0\" >0.734</td>\n      <td id=\"T_be39e_row3_col1\" class=\"data row3 col1\" >-1.357</td>\n      <td id=\"T_be39e_row3_col2\" class=\"data row3 col2\" >0.053</td>\n      <td id=\"T_be39e_row3_col3\" class=\"data row3 col3\" >0.002</td>\n      <td id=\"T_be39e_row3_col4\" class=\"data row3 col4\" >0.160</td>\n      <td id=\"T_be39e_row3_col5\" class=\"data row3 col5\" >0.086</td>\n      <td id=\"T_be39e_row3_col6\" class=\"data row3 col6\" >0.279</td>\n      <td id=\"T_be39e_row3_col7\" class=\"data row3 col7\" >225567.465</td>\n      <td id=\"T_be39e_row3_col8\" class=\"data row3 col8\" >0.487</td>\n      <td id=\"T_be39e_row3_col9\" class=\"data row3 col9\" >147.912</td>\n    </tr>\n    <tr>\n      <th id=\"T_be39e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_be39e_row4_col0\" class=\"data row4 col0\" >0.533</td>\n      <td id=\"T_be39e_row4_col1\" class=\"data row4 col1\" >-13.056</td>\n      <td id=\"T_be39e_row4_col2\" class=\"data row4 col2\" >0.024</td>\n      <td id=\"T_be39e_row4_col3\" class=\"data row4 col3\" >0.069</td>\n      <td id=\"T_be39e_row4_col4\" class=\"data row4 col4\" >0.000</td>\n      <td id=\"T_be39e_row4_col5\" class=\"data row4 col5\" >0.331</td>\n      <td id=\"T_be39e_row4_col6\" class=\"data row4 col6\" >0.478</td>\n      <td id=\"T_be39e_row4_col7\" class=\"data row4 col7\" >213960.679</td>\n      <td id=\"T_be39e_row4_col8\" class=\"data row4 col8\" >0.947</td>\n      <td id=\"T_be39e_row4_col9\" class=\"data row4 col9\" >89.585</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}},{"name":"stdout","text":"\u001b[36m--------------------------------------------------\nTesting data head:\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7c182e717690>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_96bc8\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_96bc8_level0_col0\" class=\"col_heading level0 col0\" >RhythmScore</th>\n      <th id=\"T_96bc8_level0_col1\" class=\"col_heading level0 col1\" >AudioLoudness</th>\n      <th id=\"T_96bc8_level0_col2\" class=\"col_heading level0 col2\" >VocalContent</th>\n      <th id=\"T_96bc8_level0_col3\" class=\"col_heading level0 col3\" >AcousticQuality</th>\n      <th id=\"T_96bc8_level0_col4\" class=\"col_heading level0 col4\" >InstrumentalScore</th>\n      <th id=\"T_96bc8_level0_col5\" class=\"col_heading level0 col5\" >LivePerformanceLikelihood</th>\n      <th id=\"T_96bc8_level0_col6\" class=\"col_heading level0 col6\" >MoodScore</th>\n      <th id=\"T_96bc8_level0_col7\" class=\"col_heading level0 col7\" >TrackDurationMs</th>\n      <th id=\"T_96bc8_level0_col8\" class=\"col_heading level0 col8\" >Energy</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >id</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n      <th class=\"blank col3\" >&nbsp;</th>\n      <th class=\"blank col4\" >&nbsp;</th>\n      <th class=\"blank col5\" >&nbsp;</th>\n      <th class=\"blank col6\" >&nbsp;</th>\n      <th class=\"blank col7\" >&nbsp;</th>\n      <th class=\"blank col8\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_96bc8_level0_row0\" class=\"row_heading level0 row0\" >524164</th>\n      <td id=\"T_96bc8_row0_col0\" class=\"data row0 col0\" >0.410</td>\n      <td id=\"T_96bc8_row0_col1\" class=\"data row0 col1\" >-16.795</td>\n      <td id=\"T_96bc8_row0_col2\" class=\"data row0 col2\" >0.024</td>\n      <td id=\"T_96bc8_row0_col3\" class=\"data row0 col3\" >0.233</td>\n      <td id=\"T_96bc8_row0_col4\" class=\"data row0 col4\" >0.013</td>\n      <td id=\"T_96bc8_row0_col5\" class=\"data row0 col5\" >0.272</td>\n      <td id=\"T_96bc8_row0_col6\" class=\"data row0 col6\" >0.664</td>\n      <td id=\"T_96bc8_row0_col7\" class=\"data row0 col7\" >302901.550</td>\n      <td id=\"T_96bc8_row0_col8\" class=\"data row0 col8\" >0.425</td>\n    </tr>\n    <tr>\n      <th id=\"T_96bc8_level0_row1\" class=\"row_heading level0 row1\" >524165</th>\n      <td id=\"T_96bc8_row1_col0\" class=\"data row1 col0\" >0.463</td>\n      <td id=\"T_96bc8_row1_col1\" class=\"data row1 col1\" >-1.357</td>\n      <td id=\"T_96bc8_row1_col2\" class=\"data row1 col2\" >0.142</td>\n      <td id=\"T_96bc8_row1_col3\" class=\"data row1 col3\" >0.058</td>\n      <td id=\"T_96bc8_row1_col4\" class=\"data row1 col4\" >0.258</td>\n      <td id=\"T_96bc8_row1_col5\" class=\"data row1 col5\" >0.098</td>\n      <td id=\"T_96bc8_row1_col6\" class=\"data row1 col6\" >0.830</td>\n      <td id=\"T_96bc8_row1_col7\" class=\"data row1 col7\" >221995.664</td>\n      <td id=\"T_96bc8_row1_col8\" class=\"data row1 col8\" >0.846</td>\n    </tr>\n    <tr>\n      <th id=\"T_96bc8_level0_row2\" class=\"row_heading level0 row2\" >524166</th>\n      <td id=\"T_96bc8_row2_col0\" class=\"data row2 col0\" >0.687</td>\n      <td id=\"T_96bc8_row2_col1\" class=\"data row2 col1\" >-3.369</td>\n      <td id=\"T_96bc8_row2_col2\" class=\"data row2 col2\" >0.168</td>\n      <td id=\"T_96bc8_row2_col3\" class=\"data row2 col3\" >0.288</td>\n      <td id=\"T_96bc8_row2_col4\" class=\"data row2 col4\" >0.211</td>\n      <td id=\"T_96bc8_row2_col5\" class=\"data row2 col5\" >0.326</td>\n      <td id=\"T_96bc8_row2_col6\" class=\"data row2 col6\" >0.305</td>\n      <td id=\"T_96bc8_row2_col7\" class=\"data row2 col7\" >357724.013</td>\n      <td id=\"T_96bc8_row2_col8\" class=\"data row2 col8\" >0.134</td>\n    </tr>\n    <tr>\n      <th id=\"T_96bc8_level0_row3\" class=\"row_heading level0 row3\" >524167</th>\n      <td id=\"T_96bc8_row3_col0\" class=\"data row3 col0\" >0.886</td>\n      <td id=\"T_96bc8_row3_col1\" class=\"data row3 col1\" >-5.598</td>\n      <td id=\"T_96bc8_row3_col2\" class=\"data row3 col2\" >0.118</td>\n      <td id=\"T_96bc8_row3_col3\" class=\"data row3 col3\" >0.000</td>\n      <td id=\"T_96bc8_row3_col4\" class=\"data row3 col4\" >0.377</td>\n      <td id=\"T_96bc8_row3_col5\" class=\"data row3 col5\" >0.134</td>\n      <td id=\"T_96bc8_row3_col6\" class=\"data row3 col6\" >0.488</td>\n      <td id=\"T_96bc8_row3_col7\" class=\"data row3 col7\" >271790.399</td>\n      <td id=\"T_96bc8_row3_col8\" class=\"data row3 col8\" >0.316</td>\n    </tr>\n    <tr>\n      <th id=\"T_96bc8_level0_row4\" class=\"row_heading level0 row4\" >524168</th>\n      <td id=\"T_96bc8_row4_col0\" class=\"data row4 col0\" >0.637</td>\n      <td id=\"T_96bc8_row4_col1\" class=\"data row4 col1\" >-7.068</td>\n      <td id=\"T_96bc8_row4_col2\" class=\"data row4 col2\" >0.126</td>\n      <td id=\"T_96bc8_row4_col3\" class=\"data row4 col3\" >0.539</td>\n      <td id=\"T_96bc8_row4_col4\" class=\"data row4 col4\" >0.069</td>\n      <td id=\"T_96bc8_row4_col5\" class=\"data row4 col5\" >0.024</td>\n      <td id=\"T_96bc8_row4_col6\" class=\"data row4 col6\" >0.591</td>\n      <td id=\"T_96bc8_row4_col7\" class=\"data row4 col7\" >277728.538</td>\n      <td id=\"T_96bc8_row4_col8\" class=\"data row4 col8\" >0.481</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}},{"name":"stdout","text":"\u001b[35m--------------------------------------------------\nInformation and description\u001b[0m\n\u001b[34m--------------------------------------------------\nTraining data description:\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       RhythmScore  AudioLoudness  VocalContent  AcousticQuality  \\\ncount    524164.00      524164.00     524164.00        524164.00   \nmean          0.63          -8.38          0.07             0.26   \nstd           0.16           4.62          0.05             0.22   \nmin           0.08         -27.51          0.02             0.00   \n25%           0.52         -11.55          0.02             0.07   \n50%           0.63          -8.25          0.07             0.24   \n75%           0.74          -4.91          0.11             0.40   \nmax           0.98          -1.36          0.26             1.00   \n\n       InstrumentalScore  LivePerformanceLikelihood  MoodScore  \\\ncount          524164.00                  524164.00  524164.00   \nmean                0.12                       0.18       0.56   \nstd                 0.13                       0.12       0.23   \nmin                 0.00                       0.02       0.03   \n25%                 0.00                       0.08       0.40   \n50%                 0.07                       0.17       0.56   \n75%                 0.20                       0.27       0.72   \nmax                 0.87                       0.60       0.98   \n\n       TrackDurationMs     Energy  \ncount        524164.00  524164.00  \nmean         241903.69       0.50  \nstd           59326.60       0.29  \nmin           63973.00       0.00  \n25%          207099.88       0.25  \n50%          243684.06       0.51  \n75%          281851.66       0.75  \nmax          464723.23       1.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RhythmScore</th>\n      <th>AudioLoudness</th>\n      <th>VocalContent</th>\n      <th>AcousticQuality</th>\n      <th>InstrumentalScore</th>\n      <th>LivePerformanceLikelihood</th>\n      <th>MoodScore</th>\n      <th>TrackDurationMs</th>\n      <th>Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>524164.00</td>\n      <td>524164.00</td>\n      <td>524164.00</td>\n      <td>524164.00</td>\n      <td>524164.00</td>\n      <td>524164.00</td>\n      <td>524164.00</td>\n      <td>524164.00</td>\n      <td>524164.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.63</td>\n      <td>-8.38</td>\n      <td>0.07</td>\n      <td>0.26</td>\n      <td>0.12</td>\n      <td>0.18</td>\n      <td>0.56</td>\n      <td>241903.69</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.16</td>\n      <td>4.62</td>\n      <td>0.05</td>\n      <td>0.22</td>\n      <td>0.13</td>\n      <td>0.12</td>\n      <td>0.23</td>\n      <td>59326.60</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.08</td>\n      <td>-27.51</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>63973.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.52</td>\n      <td>-11.55</td>\n      <td>0.02</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.08</td>\n      <td>0.40</td>\n      <td>207099.88</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.63</td>\n      <td>-8.25</td>\n      <td>0.07</td>\n      <td>0.24</td>\n      <td>0.07</td>\n      <td>0.17</td>\n      <td>0.56</td>\n      <td>243684.06</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.74</td>\n      <td>-4.91</td>\n      <td>0.11</td>\n      <td>0.40</td>\n      <td>0.20</td>\n      <td>0.27</td>\n      <td>0.72</td>\n      <td>281851.66</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.98</td>\n      <td>-1.36</td>\n      <td>0.26</td>\n      <td>1.00</td>\n      <td>0.87</td>\n      <td>0.60</td>\n      <td>0.98</td>\n      <td>464723.23</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\u001b[34m--------------------------------------------------\nTraining data information:\u001b[0m\n<class 'pandas.core.frame.DataFrame'>\nIndex: 524164 entries, 0 to 524163\nData columns (total 10 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   RhythmScore                524164 non-null  float64\n 1   AudioLoudness              524164 non-null  float64\n 2   VocalContent               524164 non-null  float64\n 3   AcousticQuality            524164 non-null  float64\n 4   InstrumentalScore          524164 non-null  float64\n 5   LivePerformanceLikelihood  524164 non-null  float64\n 6   MoodScore                  524164 non-null  float64\n 7   TrackDurationMs            524164 non-null  float64\n 8   Energy                     524164 non-null  float64\n 9   BeatsPerMinute             524164 non-null  float64\ndtypes: float64(10)\nmemory usage: 44.0 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"\u001b[34m--------------------------------------------------\nTesting data description:\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       RhythmScore  AudioLoudness  VocalContent  AcousticQuality  \\\ncount    174722.00      174722.00     174722.00        174722.00   \nmean          0.63          -8.38          0.07             0.26   \nstd           0.16           4.62          0.05             0.22   \nmin           0.14         -27.44          0.02             0.00   \n25%           0.51         -11.55          0.02             0.07   \n50%           0.63          -8.25          0.07             0.24   \n75%           0.74          -4.90          0.11             0.40   \nmax           0.98          -1.36          0.26             1.00   \n\n       InstrumentalScore  LivePerformanceLikelihood  MoodScore  \\\ncount          174722.00                  174722.00  174722.00   \nmean                0.12                       0.18       0.56   \nstd                 0.13                       0.12       0.23   \nmin                 0.00                       0.02       0.03   \n25%                 0.00                       0.08       0.40   \n50%                 0.07                       0.17       0.57   \n75%                 0.20                       0.27       0.72   \nmax                 0.68                       0.60       0.98   \n\n       TrackDurationMs     Energy  \ncount        174722.00  174722.00  \nmean         241753.74       0.50  \nstd           59103.90       0.29  \nmin           63973.00       0.00  \n25%          207518.15       0.25  \n50%          243584.59       0.51  \n75%          281737.45       0.75  \nmax          449288.81       1.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RhythmScore</th>\n      <th>AudioLoudness</th>\n      <th>VocalContent</th>\n      <th>AcousticQuality</th>\n      <th>InstrumentalScore</th>\n      <th>LivePerformanceLikelihood</th>\n      <th>MoodScore</th>\n      <th>TrackDurationMs</th>\n      <th>Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>174722.00</td>\n      <td>174722.00</td>\n      <td>174722.00</td>\n      <td>174722.00</td>\n      <td>174722.00</td>\n      <td>174722.00</td>\n      <td>174722.00</td>\n      <td>174722.00</td>\n      <td>174722.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.63</td>\n      <td>-8.38</td>\n      <td>0.07</td>\n      <td>0.26</td>\n      <td>0.12</td>\n      <td>0.18</td>\n      <td>0.56</td>\n      <td>241753.74</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.16</td>\n      <td>4.62</td>\n      <td>0.05</td>\n      <td>0.22</td>\n      <td>0.13</td>\n      <td>0.12</td>\n      <td>0.23</td>\n      <td>59103.90</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.14</td>\n      <td>-27.44</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>63973.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.51</td>\n      <td>-11.55</td>\n      <td>0.02</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.08</td>\n      <td>0.40</td>\n      <td>207518.15</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.63</td>\n      <td>-8.25</td>\n      <td>0.07</td>\n      <td>0.24</td>\n      <td>0.07</td>\n      <td>0.17</td>\n      <td>0.57</td>\n      <td>243584.59</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.74</td>\n      <td>-4.90</td>\n      <td>0.11</td>\n      <td>0.40</td>\n      <td>0.20</td>\n      <td>0.27</td>\n      <td>0.72</td>\n      <td>281737.45</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.98</td>\n      <td>-1.36</td>\n      <td>0.26</td>\n      <td>1.00</td>\n      <td>0.68</td>\n      <td>0.60</td>\n      <td>0.98</td>\n      <td>449288.81</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\u001b[34m--------------------------------------------------\nTesting data information:\u001b[0m\n<class 'pandas.core.frame.DataFrame'>\nIndex: 174722 entries, 524164 to 698885\nData columns (total 9 columns):\n #   Column                     Non-Null Count   Dtype  \n---  ------                     --------------   -----  \n 0   RhythmScore                174722 non-null  float64\n 1   AudioLoudness              174722 non-null  float64\n 2   VocalContent               174722 non-null  float64\n 3   AcousticQuality            174722 non-null  float64\n 4   InstrumentalScore          174722 non-null  float64\n 5   LivePerformanceLikelihood  174722 non-null  float64\n 6   MoodScore                  174722 non-null  float64\n 7   TrackDurationMs            174722 non-null  float64\n 8   Energy                     174722 non-null  float64\ndtypes: float64(9)\nmemory usage: 13.3 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"\u001b[34m--------------------------------------------------\nUnique and null values:\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7c17e9985ed0>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_42b9b\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_42b9b_level0_col0\" class=\"col_heading level0 col0\" >RhythmScore</th>\n      <th id=\"T_42b9b_level0_col1\" class=\"col_heading level0 col1\" >AudioLoudness</th>\n      <th id=\"T_42b9b_level0_col2\" class=\"col_heading level0 col2\" >VocalContent</th>\n      <th id=\"T_42b9b_level0_col3\" class=\"col_heading level0 col3\" >AcousticQuality</th>\n      <th id=\"T_42b9b_level0_col4\" class=\"col_heading level0 col4\" >InstrumentalScore</th>\n      <th id=\"T_42b9b_level0_col5\" class=\"col_heading level0 col5\" >LivePerformanceLikelihood</th>\n      <th id=\"T_42b9b_level0_col6\" class=\"col_heading level0 col6\" >MoodScore</th>\n      <th id=\"T_42b9b_level0_col7\" class=\"col_heading level0 col7\" >TrackDurationMs</th>\n      <th id=\"T_42b9b_level0_col8\" class=\"col_heading level0 col8\" >Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_42b9b_level0_row0\" class=\"row_heading level0 row0\" >Training_Nunq</th>\n      <td id=\"T_42b9b_row0_col0\" class=\"data row0 col0\" >322528</td>\n      <td id=\"T_42b9b_row0_col1\" class=\"data row0 col1\" >310411</td>\n      <td id=\"T_42b9b_row0_col2\" class=\"data row0 col2\" >229305</td>\n      <td id=\"T_42b9b_row0_col3\" class=\"data row0 col3\" >270478</td>\n      <td id=\"T_42b9b_row0_col4\" class=\"data row0 col4\" >218979</td>\n      <td id=\"T_42b9b_row0_col5\" class=\"data row0 col5\" >279591</td>\n      <td id=\"T_42b9b_row0_col6\" class=\"data row0 col6\" >306504</td>\n      <td id=\"T_42b9b_row0_col7\" class=\"data row0 col7\" >377442</td>\n      <td id=\"T_42b9b_row0_col8\" class=\"data row0 col8\" >11606</td>\n    </tr>\n    <tr>\n      <th id=\"T_42b9b_level0_row1\" class=\"row_heading level0 row1\" >Testing_Nunq</th>\n      <td id=\"T_42b9b_row1_col0\" class=\"data row1 col0\" >116151</td>\n      <td id=\"T_42b9b_row1_col1\" class=\"data row1 col1\" >110402</td>\n      <td id=\"T_42b9b_row1_col2\" class=\"data row1 col2\" >84370</td>\n      <td id=\"T_42b9b_row1_col3\" class=\"data row1 col3\" >97364</td>\n      <td id=\"T_42b9b_row1_col4\" class=\"data row1 col4\" >79221</td>\n      <td id=\"T_42b9b_row1_col5\" class=\"data row1 col5\" >101149</td>\n      <td id=\"T_42b9b_row1_col6\" class=\"data row1 col6\" >109993</td>\n      <td id=\"T_42b9b_row1_col7\" class=\"data row1 col7\" >133624</td>\n      <td id=\"T_42b9b_row1_col8\" class=\"data row1 col8\" >10465</td>\n    </tr>\n    <tr>\n      <th id=\"T_42b9b_level0_row2\" class=\"row_heading level0 row2\" >Training_Nulls</th>\n      <td id=\"T_42b9b_row2_col0\" class=\"data row2 col0\" >0</td>\n      <td id=\"T_42b9b_row2_col1\" class=\"data row2 col1\" >0</td>\n      <td id=\"T_42b9b_row2_col2\" class=\"data row2 col2\" >0</td>\n      <td id=\"T_42b9b_row2_col3\" class=\"data row2 col3\" >0</td>\n      <td id=\"T_42b9b_row2_col4\" class=\"data row2 col4\" >0</td>\n      <td id=\"T_42b9b_row2_col5\" class=\"data row2 col5\" >0</td>\n      <td id=\"T_42b9b_row2_col6\" class=\"data row2 col6\" >0</td>\n      <td id=\"T_42b9b_row2_col7\" class=\"data row2 col7\" >0</td>\n      <td id=\"T_42b9b_row2_col8\" class=\"data row2 col8\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_42b9b_level0_row3\" class=\"row_heading level0 row3\" >Testing_Nulls</th>\n      <td id=\"T_42b9b_row3_col0\" class=\"data row3 col0\" >0</td>\n      <td id=\"T_42b9b_row3_col1\" class=\"data row3 col1\" >0</td>\n      <td id=\"T_42b9b_row3_col2\" class=\"data row3 col2\" >0</td>\n      <td id=\"T_42b9b_row3_col3\" class=\"data row3 col3\" >0</td>\n      <td id=\"T_42b9b_row3_col4\" class=\"data row3 col4\" >0</td>\n      <td id=\"T_42b9b_row3_col5\" class=\"data row3 col5\" >0</td>\n      <td id=\"T_42b9b_row3_col6\" class=\"data row3 col6\" >0</td>\n      <td id=\"T_42b9b_row3_col7\" class=\"data row3 col7\" >0</td>\n      <td id=\"T_42b9b_row3_col8\" class=\"data row3 col8\" >0</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"#### **5. PREPARE FEATURES**\n\nThis section focuses on feature engineering before modeling. An additional function, add_features, is used for this purpose.\n\nFirst, a dictionary called new_features is created to store the generated columns. We loop over all pairwise combinations of existing features, performing multiplication and division (adding 1e-6 to denominators to avoid division by zero). Another loop generates new columns by multiplying all triplet combinations of features.\n\nNext, for each column, two features are created to indicate the quartile and decile in which the values fall. This is done using pd.cut with 4 and 10 bins, respectively, without labels to produce integers, and including the lowest value. This works because all columns are numerical and contain no missing values.\n\nFinally, the dictionary with the created features is converted to a DataFrame with the same index as the training or testing dataset, to be concatenated as new columns.\n\nBefore applying this function to both training and testing datasets, the target variable is stored separately and removed from the training dataset to ensure it is excluded from feature calculations.\n","metadata":{}},{"cell_type":"code","source":"# ===== PREPARE FEATURES =====\ndef add_features(df):\n    new_features = {}\n    for col1, col2 in list(combinations(df.columns, 2)):\n        new_features[f\"{col1}_m_{col2}\"] = df[col1] * df[col2]\n        new_features[f\"{col1}_d_{col2}\"] = df[col1] / (df[col2] + 1e-6)\n\n    for col1, col2, col3 in list(combinations(df.columns, 3)):\n        new_features[f\"{col1}_m_{col2}_m_{col3}\"] = df[col1] * df[col2] * df[col3]\n\n    for col in df.columns:\n        new_features[f\"{col}_quartile\"] = pd.cut(df[col], bins=4, labels=False, include_lowest=True)\n        new_features[f\"{col}_decile\"] = pd.cut(df[col], bins=10, labels=False, include_lowest=True)\n\n    df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)\n    return df\n\ny = X['BeatsPerMinute']\nX = X.drop(['BeatsPerMinute'], axis=1)\n\nX = add_features(X)\nX_test = add_features(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:11:33.919993Z","iopub.execute_input":"2025-09-07T16:11:33.920360Z","iopub.status.idle":"2025-09-07T16:11:36.316641Z","shell.execute_reply.started":"2025-09-07T16:11:33.920326Z","shell.execute_reply":"2025-09-07T16:11:36.315656Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"#### **6. XGBOOST MODEL**\n\nIn this step, the XGBoost model is defined. The objective is set to regression, using squared error as the loss function, and the evaluation metric during training and validation is root mean squared error (RMSE). A total of 1000 trees are used to allow sufficient learning without overfitting, with each tree limited to a maximum depth of 6 to control complexity. A learning rate of 0.002 ensures slow and stable learning.\n\nFor each tree, two-thirds of the features are used, and for each node, two-thirds of the features are sampled via the colsample_bytree and colsample_bynode parameters. L1 and L2 regularization are applied by setting reg_alpha to 2.50 and reg_lambda to 0.85 to penalize large leaf outputs. Finally, a random state is set for reproducibility.","metadata":{}},{"cell_type":"code","source":"# ===== XGBOOST MODEL =====\nxgb = XGBRegressor(\n    objective = 'reg:squarederror',\n    eval_metric = 'rmse',\n    n_estimators = 1000,\n    max_depth = 6,\n    learning_rate = 0.002,\n    colsample_bytree = 0.67,\n    colsample_bynode = 0.67,\n    reg_alpha = 2.50,\n    reg_lambda = 0.85,\n    random_state = 42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:11:38.960855Z","iopub.execute_input":"2025-09-07T16:11:38.961128Z","iopub.status.idle":"2025-09-07T16:11:38.965911Z","shell.execute_reply.started":"2025-09-07T16:11:38.961110Z","shell.execute_reply":"2025-09-07T16:11:38.964827Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"#### **7. LIGHTGBM MODEL**\n\nIn this step, we define the hyperparameters for the LightGBM model. A total of 1000 trees are used to allow sufficient learning without overfitting. Each tree’s depth is limited to 14, and the number of leaves is limited to 85, which is relatively high and allows the model to capture complex interactions. A low learning rate of 0.0015 ensures slow and stable learning.\n\nFor each tree, 90% of the features and 90% of the rows are used, controlled by the feature_fraction and subsample parameters. This introduces randomness and improves generalization. Large leaf outputs are slightly penalized by setting reg_alpha and reg_lambda to 0.0001. Finally, a random state is set for reproducibility, and verbosity is set to -1 to silence output during training.","metadata":{}},{"cell_type":"code","source":"# ===== LIGHTGBM MODEL =====\nlgbm = LGBMRegressor(\n    n_estimators = 1000,\n    max_depth = 14,\n    num_leaves = 85,\n    learning_rate = 0.0015,\n    feature_fraction = 0.90,\n    subsample = 0.90,\n    reg_alpha = 0.0001,\n    reg_lambda = 0.0001,\n    random_state = 42,\n    verbosity = -1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:11:40.566944Z","iopub.execute_input":"2025-09-07T16:11:40.567815Z","iopub.status.idle":"2025-09-07T16:11:40.572210Z","shell.execute_reply.started":"2025-09-07T16:11:40.567786Z","shell.execute_reply":"2025-09-07T16:11:40.571396Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"#### **8. 5-FOLD CROSS-VALIDATION**\n\nWe use 5-fold cross-validation to train the models. First, two dictionaries are created to store predictions: oof_preds will hold out-of-fold predictions on the training data, and test_preds will store predictions on the testing data, averaged across folds. Each dictionary has a key for each model, with values as NumPy arrays of appropriate lengths initialized to zero.\n\nNext, an instance of KFold is created with 5 splits, shuffling enabled to promote generalization, and a fixed random state for reproducibility.\n\nFor each fold, the data is split into training and validation sets. The XGBoost and LightGBM models are fitted on the training set, with XGBoost’s verbose output silenced. We then loop over both models to generate out-of-fold predictions on the validation set and predictions on the test data, which are averaged across folds.\n\nAfter all folds are completed, the out-of-fold predictions of both models are compared with the true targets, and the cross-validation RMSE is calculated.","metadata":{}},{"cell_type":"code","source":"# ===== 5-FOLD CROSS-VALIDATION =====\noof_preds = {'XGBoost': np.zeros(len(X)), 'LightGBM': np.zeros(len(X))}\ntest_preds = {'XGBoost': np.zeros(len(X_test)), 'LightGBM': np.zeros(len(X_test))}\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor (train_idx, valid_idx) in kf.split(X, y):\n    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n    xgb.fit(X_train, y_train, verbose=False)\n    lgbm.fit(X_train, y_train)\n\n    for name, model in [('XGBoost', xgb), ('LightGBM', lgbm)]:\n        oof_preds[name][valid_idx] = model.predict(X_valid)\n        test_preds[name] += model.predict(X_test) / kf.n_splits\n\nfor model in ['XGBoost', 'LightGBM']:\n    rmse = np.sqrt(mean_squared_error(y, oof_preds[model]))\n    print(f'{Fore.RED}{model} predictions - RMSE score: {rmse:.6f}{Style.RESET_ALL}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:16:57.895612Z","iopub.execute_input":"2025-09-07T16:16:57.895938Z","iopub.status.idle":"2025-09-07T16:46:03.369272Z","shell.execute_reply.started":"2025-09-07T16:16:57.895918Z","shell.execute_reply":"2025-09-07T16:46:03.368381Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mXGBoost predictions - RMSE score: 26.461237\u001b[0m\n\u001b[31mLightGBM predictions - RMSE score: 26.460378\u001b[0m\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"#### **9. BLENDING**\n\nIn this step, both the out-of-fold predictions and the test-set predictions are averaged across the two models. We then calculate the new cross-validation RMSE by comparing the averaged out-of-fold predictions with the true target values.","metadata":{}},{"cell_type":"code","source":"# ===== BLENDING =====\navg_oof_preds = (oof_preds['XGBoost'] + oof_preds['LightGBM']) / 2\navg_test_preds = (test_preds['XGBoost'] + test_preds['LightGBM']) / 2\n\nrmse = np.sqrt(mean_squared_error(y, avg_oof_preds))\nprint(f'{Fore.RED}Averaged predictions - RMSE score: {rmse:.6f}{Style.RESET_ALL}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:47:21.065895Z","iopub.execute_input":"2025-09-07T16:47:21.066205Z","iopub.status.idle":"2025-09-07T16:47:21.078012Z","shell.execute_reply.started":"2025-09-07T16:47:21.066180Z","shell.execute_reply":"2025-09-07T16:47:21.077092Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mAveraged predictions - RMSE score: 26.460300\u001b[0m\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"#### **10. CREATE SUBMISSION FILE**\n\nThe final step is creating a CSV file for submission to the competition.","metadata":{}},{"cell_type":"code","source":"# ===== CREATE SUBMISSION FILE =====\noutput = pd.DataFrame({'id': X_test.index, 'y': avg_test_preds})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T16:47:25.363063Z","iopub.execute_input":"2025-09-07T16:47:25.363352Z","iopub.status.idle":"2025-09-07T16:47:25.763930Z","shell.execute_reply.started":"2025-09-07T16:47:25.363331Z","shell.execute_reply":"2025-09-07T16:47:25.763244Z"}},"outputs":[],"execution_count":18}]}